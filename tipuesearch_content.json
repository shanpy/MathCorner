{"pages":[{"url":"http://shanpy.github.io/mathcorner/cfa-level1-reading-note-5.html","text":"Part 2: Interest Rates: Interpretation Time value of money concerns equivalence relationships between cash flows occurring on different dates. If you pay \\ \\(10,000 one year from today and in return receive \\\\) 9,500 today, this can be a fair trade because you discount the \\$ 10,000 received in one year. i.e. cutting its values based on how much times passes before the money is paid. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"CFA","title":"2016 CFA Level 1 Reading Note - Reading 5"},{"url":"http://shanpy.github.io/mathcorner/an-introduction-to-think-stats-chapter-1.html","text":"Chapter 1: Exploratory Data Analysis Anecdotal Evidence is the evidence based on the data that is unpublished and usually personal, rather than by a well-designed study. Anecdotal Evidence usually fails because of four reasons: Small Number of Observations Selection Bias: people who discuss the question may be interested in one aspects of the answer Confirmation Bias: people who belive the claim might be more likely to contribute examples that confirm it Inaccuracy: Anecdotes are ofter personal, so there exists misremembered, misrepeated, etc. To avoid Anecdotal Evidence, a few tools of statistics can be used: Data Collection: large and trustable data source Descriptive Statistics: statistics that summarize data concisely, maybe with data virtualization Exploratory Data Analysis: patterns, differnces and other features that address the question. Inconsistency and Identify limitations. Estimation: use data from sample to estimate characteristics Hypothesis Testing: if there is any apparent effects, such as a difference between two groups, evaluate if this effect happening by chance. Population : a group we are interested in studying. Cross-Sectional Study : captures a snapshot of a group at a point in time. It is representative , which means every number of the target population has an equal change of participating. Oversampled is opposite to representative. It means some groups of population has much higher rate in all sample groups. Oversampling is used to avoid errors due to small sample sizes. Longitudinal Study : observes a group repeatedly over a period of time. Cycle : a survey can be conducted several times. Each deployment is called a cycle. Sample : data from a subset of population Record : In a dataset, a collection of information about a single person or other subject. Respondents : people who participate in the survey DataFrame : the fundamental data structure provided by pandas . It contains a row of each record, and the variable names and their types. It also provides methods of accessing and modifying data. Raw Data : values collected with little or no checking, calculation or interpretation. Recodes : instead of being part of raw data, recodes are calculated by raw data. Recodes are often based on logic that checks the consistency and accuracy of the data. Data Cleaning : operations such as check for errors, deal with sepecial values, convert data into different formats and perform calculations after you import data. Data Validation : one way to validate data is to compute basic statistics and compare them with published results Data Interpretation : To work with data effectively, you have to think on two levels at the same time: the level of statistics and the level of context . Some result is statistically acceptable but not natual in context.","tags":"Data Science","title":"An Introduction to Think Stats - Chapter 1"},{"url":"http://shanpy.github.io/mathcorner/probabilistic-programming-and-bayesian-methods-for-hacker-reading-note-chapter-1.html","text":"This post is being transferred from my old blog site , about Python development for statistics. The Philosophy of Bayesian Inference Bayesian inference is simply updating your beliefs after considering new evidence. We update our beliefs about an outcome; ralely can we be absolutely sure unless we rule out all other alternatives. In Bayesian, the probability is consideres as believablity of an event. i.e. how confident we are. Frequentist : assume probablity is the long-run frequency of events. Bayesian : asssume probablity is a measure of belief . Note that belief is assigneed individually , which means there can be conflicting of blieves. P(A) : prior probability P(A|X) : the probablity of A given the evidence X For example: P(A) : The code likely has a bug with it. P(A|X) : The code passed all X tests, there still might be a bug, but its presence is less likely now Every time after a new evidence X comes, we re-weighted the prior probablity to incorporated the new evidence. After this process, our guesses become less wrong . i.e. we try to be more right after each guess. Frequentist will return a number, while Bayesians will return probablity. Forthe example above, if asking \"My code passes all tests. Is my code bug-free?\", Frequentist will return yes. If asking \" Often my code has bugs. (prior parameter) My code passed all X tests. Is my code bug-free?\", Bayesians will return \"Yes, with probablity 0.8; No, with probablity 0.2\". Denote N as the number of instances of evidence we possess. As we gather an infinite amount of evidence, say as N -> Infinity , our Bayesian results (often) align with frequentist results. So for large N , statistical inference is more or less objective For small N , inference is much more unstable : Frequentist estimates have more variance and larger confidence intervals. Hence Bayesians introduce a prior and returning probablities , it can preserve the uncentainty that reflects the instability (not stable) of statistical inference of a small N dataset. Bayes' Theorem if our code passes X tests, we want to update our belief to incorporate this. We call this new belief the posterior probability . Bayes' Theorem is used for updating process. Bayesian inference merely uses it to connect prior probabilities P(A) with an updated posterior probabilities P(A|X) . The Understanding of Variables for Coding Example Assume A means the event that code has no bug and X means code passes X tests. Assume P(A) = p . P(A|X) : the probability for no bugs, giving passing debug test X . P(X|A) : the probability that code passes X test given there is no bugs. This always be 1. #Since We can get P(X) by following way: P ( X ) = P ( X and A ) + P ( X and ~ A ( not A )) = P ( X | A ) P ( A ) + P ( X |~ A ) P ( ~ A ) = P ( X | A ) p + P ( X |~ A )( 1 - p ) #Assume P(X|~A) = 0.5 here, and we know P(X|A) = 1 P ( A | X ) = 1 * p / ( 1 * p + 0.5 * ( 1 - p )) #This is the posterior probability Probability Distributions Let Z be some random variable. Then associated with Z is a probability distribution function that assigns probablities to the different outcomes Z can take. A probability distribution is a curve where the probability of an outcome is proportional to the height of the curve. Z can be discreate: only assume values on a speical list. Such as populations, movie ratings, etc. Z can be continous: takes aribitrarily exact values. Such as temporature, speed, etc Z can be mixed by two types above. If Z is discreate If Z is discreate, its distribution is called probability mass function , which measures the probablity Z takes on the value k , denoted P(Z=k) . We saw Z is posisson-distributed if: Î» is called a parameter of the distribution, or intensity of the possison distribution and it controls the distribution's shape . Here, Î» can be any positive number. if Î» increate, add probability to larger values. if Î» decrease, add probability to smaller values. k must be a non-negative integer. If a random variable Z has a poisson mass distribution , we can express as: Z ~ Poi(Î») For a poisson distribution, its expected value is equal to its parameter, i.e. E[Z | Î»] = Î» If Z is continuous If Z is continous, its distribution is called probability density function . z can only take non-negative value, including non-integer If Z has an exponential distribution, we say Z is exponential and we have: Z ~ Exp(Î») and E[Z | Î»] = 1/Î» #PyMC import pymc as pm alpha = 1.0 / count_data . mean () lambda_1 = pm . Exponential ( \"lambda_1\" , alpha ) #get lambda value lambda_2 = pm . Exponential ( \"lambda_2\" , alpha ) tau = pm . DistcreateUniform ( \"tau\" , lower = 0 , upper = n_count_data )","tags":"Data Science","title":"Probabilistic Programming and Bayesian Methods for Hackers Reading Note - Chapter 1"}]}